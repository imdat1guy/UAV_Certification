{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c930d0",
   "metadata": {},
   "source": [
    "# Analyze Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ad1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Update these values with your input csv file and output directory paths\n",
    "input= 'benchmarks.csv' \n",
    "outdir= 'perf_out'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3489a",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "646fee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Helpers ----\n",
    "\n",
    "def ensure_outdir(d: Path):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Percentiles util\n",
    "PCT = [50, 95]\n",
    "\n",
    "def pct(series):\n",
    "    return {f\"p{p}\": float(np.nanpercentile(series, p)) for p in PCT}\n",
    "\n",
    "# ---- Load & derive ----\n",
    "\n",
    "def load(input_csv: Path) -> pd.DataFrame:\n",
    "    # Identify which timestamp columns exist before parsing\n",
    "    header = pd.read_csv(input_csv, nrows=0)\n",
    "    parse_cols = [c for c in [\"submitted_at_utc\",\"included_at_utc\",\"finalized_at_utc\"] if c in header.columns]\n",
    "    df = pd.read_csv(input_csv, parse_dates=parse_cols)\n",
    "\n",
    "    # Derive latencies (seconds)\n",
    "    if \"included_at_utc\" in df.columns and \"submitted_at_utc\" in df.columns:\n",
    "        df[\"latency_inclusion_s\"] = (df[\"included_at_utc\"] - df[\"submitted_at_utc\"]).dt.total_seconds()\n",
    "    else:\n",
    "        df[\"latency_inclusion_s\"] = np.nan\n",
    "    if \"finalized_at_utc\" in df.columns and df[\"finalized_at_utc\"].notna().any():\n",
    "        df[\"latency_finality_s\"] = (df[\"finalized_at_utc\"] - df[\"submitted_at_utc\"]).dt.total_seconds()\n",
    "    else:\n",
    "        df[\"latency_finality_s\"] = np.nan\n",
    "\n",
    "    # Cost in native token\n",
    "    if \"gas_used\" in df.columns and \"effective_gas_price_wei\" in df.columns:\n",
    "        df[\"cost_native\"] = pd.to_numeric(df[\"gas_used\"], errors=\"coerce\") * pd.to_numeric(df[\"effective_gas_price_wei\"], errors=\"coerce\") / 1e18\n",
    "    else:\n",
    "        df[\"cost_native\"] = np.nan\n",
    "\n",
    "    # Success flag numeric\n",
    "    if \"success\" in df.columns:\n",
    "        df[\"success\"] = pd.to_numeric(df[\"success\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"success\"] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a4f1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Figures ----\n",
    "def cdf_xy(arr: np.ndarray):\n",
    "    x = np.sort(arr)\n",
    "    y = np.arange(1, len(x)+1) / len(x)\n",
    "    return x, y\n",
    "\n",
    "def plot_latency_cdf(df: pd.DataFrame, which: str, outpath: Path):\n",
    "    if which not in df.columns or df[which].dropna().empty:\n",
    "        return\n",
    "    plt.figure()\n",
    "    key = which\n",
    "    # âœ… Filter to successful transactions only\n",
    "    good = df[(df[\"success\"] == 1) & df[key].notna()]\n",
    "    for (net, wf), g in good.groupby([\"network\", \"workflow\"], dropna=False):\n",
    "        xs, ys = cdf_xy(g[key].values)\n",
    "        label = f\"{net}-{wf}\"\n",
    "        plt.plot(xs, ys, label=label)\n",
    "    plt.xlabel(\"Latency (s)\")\n",
    "    plt.ylabel(\"CDF\")\n",
    "    ttl = \"Latency CDF (\" + which.replace(\"_\", \" \") + \")\"\n",
    "    plt.title(ttl)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_throughput_vs_concurrency(df: pd.DataFrame, outpath: Path, uav_count_filter=None):\n",
    "    # Optional: filter for a specific UAV count (n)\n",
    "    if uav_count_filter is not None and \"uav_count\" in df.columns:\n",
    "        df = df[pd.to_numeric(df[\"uav_count\"], errors=\"coerce\") == uav_count_filter]\n",
    "        \n",
    "    # Throughput per run: successful ops / (max(included) - min(submitted))\n",
    "    rows = []\n",
    "    ok = df[df[\"success\"]==1].copy()\n",
    "    if ok.empty or \"submitted_at_utc\" not in ok or \"included_at_utc\" not in ok:\n",
    "        return\n",
    "    for (net, wf, run), g in ok.groupby([\"network\",\"workflow\",\"run_id\"], dropna=False):\n",
    "        start = g[\"submitted_at_utc\"].min()\n",
    "        end = g[\"included_at_utc\"].max()\n",
    "        dur = max((end - start).total_seconds(), 1.0)\n",
    "        ops = len(g)\n",
    "        try:\n",
    "            conc = int(pd.to_numeric(g[\"concurrency\"], errors=\"coerce\").dropna().median())\n",
    "        except Exception:\n",
    "            conc = np.nan\n",
    "        rows.append({\"network\":net, \"workflow\":wf, \"run_id\":run, \"concurrency\":conc, \"tps\": ops/dur})\n",
    "    tdf = pd.DataFrame(rows)\n",
    "    if tdf.empty:\n",
    "        return\n",
    "    plt.figure()\n",
    "    for (net, wf), g in tdf.groupby([\"network\",\"workflow\"], dropna=False):\n",
    "        g = g.sort_values(\"concurrency\")\n",
    "        plt.plot(g[\"concurrency\"], g[\"tps\"], marker=\"o\", label=f\"{net}-{wf}\")\n",
    "    plt.xlabel(\"Concurrency (clients)\")\n",
    "    plt.ylabel(\"Throughput (TPS)\")\n",
    "    plt.title(\"Throughput vs. Concurrency\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_cost_per_uav(df: pd.DataFrame, outpath: Path):\n",
    "    ok = df[df[\"success\"]==1].copy()\n",
    "    if ok.empty:\n",
    "        return\n",
    "    # Aggregate per run\n",
    "    agg = ok.groupby([\"network\",\"workflow\",\"run_id\"]).agg({\"cost_native\":\"sum\",\"uav_count\":\"max\"}).reset_index()\n",
    "    agg[\"uav_count\"] = pd.to_numeric(agg[\"uav_count\"], errors=\"coerce\")\n",
    "    agg[\"cost_per_uav_native\"] = agg[\"cost_native\"] / agg[\"uav_count\"].replace(0, np.nan)\n",
    "    plt.figure()\n",
    "    for net, g in agg.groupby(\"network\", dropna=False):\n",
    "        m = g.groupby(\"workflow\")[\"cost_per_uav_native\"].median().reset_index()\n",
    "        plt.plot(m[\"workflow\"], m[\"cost_per_uav_native\"], marker=\"o\", label=str(net))\n",
    "    plt.xlabel(\"Workflow\")\n",
    "    plt.ylabel(\"Median Cost per UAV (native token)\")\n",
    "    plt.title(\"Cost per UAV by Workflow and Network\")\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "# ---- Tables ----\n",
    "def table_latency_by_op(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Median and P95 inclusion latency by network/workflow/op_type\n",
    "    if \"latency_inclusion_s\" not in df:\n",
    "        return pd.DataFrame()\n",
    "    d = df[(df[\"success\"] == 1) & (df[\"latency_inclusion_s\"].notna())].copy()\n",
    "    if d.empty:\n",
    "        return pd.DataFrame()\n",
    "    g = d.groupby([\"network\",\"workflow\",\"op_type\"])['latency_inclusion_s']\n",
    "    out = g.agg([('p50_s', lambda s: float(np.nanpercentile(s, 50))),\n",
    "                 ('p95_s', lambda s: float(np.nanpercentile(s, 95))),\n",
    "                 ('count', 'count')]).reset_index()\n",
    "    return out\n",
    "\n",
    "def table_success_rates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = df.groupby([\"network\",\"workflow\",\"run_id\"]).agg(\n",
    "        ops=(\"success\",\"size\"),\n",
    "        ok=(\"success\", lambda s: int(np.nansum(s)))\n",
    "    ).reset_index()\n",
    "    g[\"success_rate\"] = g[\"ok\"] / g[\"ops\"]\n",
    "    return g\n",
    "\n",
    "def table_throughput(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    ok = df[df[\"success\"]==1].copy()\n",
    "    if ok.empty or \"submitted_at_utc\" not in ok or \"included_at_utc\" not in ok:\n",
    "        return pd.DataFrame()\n",
    "    for (net, wf, run), g in ok.groupby([\"network\",\"workflow\",\"run_id\"], dropna=False):\n",
    "        start = g[\"submitted_at_utc\"].min()\n",
    "        end = g[\"included_at_utc\"].max()\n",
    "        dur = max((end - start).total_seconds(), 1.0)\n",
    "        ops = len(g)\n",
    "        conc = pd.to_numeric(g[\"concurrency\"], errors=\"coerce\").dropna().median() if \"concurrency\" in g else np.nan\n",
    "        rows.append({\"network\":net, \"workflow\":wf, \"run_id\":run, \"concurrency\":conc, \"tps\": ops/dur, \"ops\":ops, \"duration_s\":dur})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def table_costs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ok = df[df[\"success\"]==1].copy()\n",
    "    if ok.empty:\n",
    "        return pd.DataFrame()\n",
    "    agg = ok.groupby([\"network\",\"workflow\",\"run_id\"]).agg({\"cost_native\":\"sum\",\"uav_count\":\"max\"}).reset_index()\n",
    "    agg[\"uav_count\"] = pd.to_numeric(agg[\"uav_count\"], errors=\"coerce\")\n",
    "    agg[\"cost_per_uav_native\"] = agg[\"cost_native\"] / agg[\"uav_count\"].replace(0, np.nan)\n",
    "    return agg\n",
    "\n",
    "def to_latex(df: pd.DataFrame, out: Path, caption: str, label: str):\n",
    "    if df.empty:\n",
    "        return\n",
    "    tex = df.to_latex(index=False, escape=True, caption=caption, label=label)\n",
    "    out.write_text(tex, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bea2d6",
   "metadata": {},
   "source": [
    "## Generate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6009dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote figures and tables to perf_out\n"
     ]
    }
   ],
   "source": [
    "input_csv = Path(input)\n",
    "outdir = Path(outdir)\n",
    "ensure_outdir(outdir)\n",
    "\n",
    "df = load(input_csv)\n",
    "\n",
    "# Save cleaned/derived\n",
    "df.to_csv(outdir / 'benchmarks_derived.csv', index=False)\n",
    "\n",
    "# Figures\n",
    "plot_latency_cdf(df, 'latency_inclusion_s', outdir / 'fig_latency_inclusion_cdf.png')\n",
    "if df['latency_finality_s'].notna().any():\n",
    "    plot_latency_cdf(df, 'latency_finality_s', outdir / 'fig_latency_finality_cdf.png')\n",
    "plot_throughput_vs_concurrency(df, outdir / 'fig_throughput_vs_concurrency.png', uav_count_filter=200)\n",
    "plot_cost_per_uav(df, outdir / 'fig_cost_per_uav.png')\n",
    "\n",
    "# Tables\n",
    "t_lat = table_latency_by_op(df)\n",
    "t_succ = table_success_rates(df)\n",
    "t_thr = table_throughput(df)\n",
    "t_cost = table_costs(df)\n",
    "\n",
    "t_lat.to_csv(outdir / 'table_latency_by_op.csv', index=False)\n",
    "t_succ.to_csv(outdir / 'table_success_rates.csv', index=False)\n",
    "t_thr.to_csv(outdir / 'table_throughput_by_run.csv', index=False)\n",
    "t_cost.to_csv(outdir / 'table_costs_by_run.csv', index=False)\n",
    "\n",
    "# Optional LaTeX tables for paper\n",
    "to_latex(t_lat, outdir / 'table_latency_by_op.tex', caption='Latency (p50/p95) by operation', label='tab:latency_by_op')\n",
    "to_latex(t_thr, outdir / 'table_throughput_by_run.tex', caption='Throughput per run', label='tab:throughput_by_run')\n",
    "to_latex(t_cost, outdir / 'table_costs_by_run.tex', caption='Cost per run and per UAV (native token)', label='tab:costs_by_run')\n",
    "\n",
    "print('Wrote figures and tables to', outdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VL-MOT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
